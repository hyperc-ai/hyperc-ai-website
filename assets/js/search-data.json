{"0": {
    "doc": "About",
    "title": "About",
    "content": ". Let computers think on their own. We’re stuck in 1970s. All of our programming and software design was invented and perfected back then. Nothing significant has changed in how we use computers in more than 40 years, they’re still just big calculators as they always were. But look at the sci-fi movies: what do space-faring races from the future do first when something goes wrong? They fix the main computer! Because computer solves problems for them. It doesn’t require step-by-step instructions. It takes a problem and outputs a solution. We need to fix our main computer if we’re going to go beyond. HyperC is the team of software engineers challenging the status quo of contemporary computing. We believe that by applying the knowledge accumulated during the last half a century to a decomposed problem, we can achieve a breakthrough required to get to the universal algorithm and universal human-machine language. Join us - info@hyperc.com . ",
    "url": "https://hyperc.ai/about/",
    "relUrl": "/about/"
  },"1": {
    "doc": "Architecture",
    "title": "Principles of HyperC",
    "content": "HyperC is loading the code as constraints as opposed to loading instructions. This allows advanced processing of logic, working with non-deterministic programs, and higher levels of ambiguity than a typical compiler or interpreter can offer. ",
    "url": "https://hyperc.ai/architecture/#principles-of-hyperc",
    "relUrl": "/architecture/#principles-of-hyperc"
  },"2": {
    "doc": "Architecture",
    "title": "Gradual Logic Grounding",
    "content": "Directly processing high-level logic of Python code and higher-level logic of database schemas is a challenging task. So HyperC takes the approach of spliting the problem into “layers” that are easier to address efficiently. Eventually, HyperC will process select grounded states to resolve remaining ambiguity with a heuristically guided grounded planner. The layers include: . | Interpreting database schema and generating Python code (e.g. interpreting unique constraints of distinct rows as mutual object inequalities with objects representing each row) | Interpreting universal constraints into Python code (like all items that match criteria must have value True) | Interpreting variable identity (same type variables in Python code may end up referring to same objects) | Symbolic execution of Python functions to create stacks for every branch (given a concrete identity branch) | Resolving other Python ambiguities like attributes with no initial value (given every branch of sym-ex) (at this point we have first-order logic actions in STRIPS-like terms) | Optimizing action schema (first-order logic and triples facts) - various proofs, splitting, etc. | Full grounding of selected states in delete-relaxed space of SAS domain (where all variables are resolved to concrete states and specific objects) | Resolving final ambiguities by finding an execution plan within grounded states using a grounded planner. | . The challenge is to apply as many optimizations as possible at every layer, including applying various machine learning techniques. ",
    "url": "https://hyperc.ai/architecture/#gradual-logic-grounding",
    "relUrl": "/architecture/#gradual-logic-grounding"
  },"3": {
    "doc": "Architecture",
    "title": "Recursive Planning",
    "content": "Any problem can be represented as a planning problem. Including the planning problem itself. So HyperC takes advantage of a decomposed planning problem to decompose even further. For example, modern approach to automatic proof includes various AI planning techniques. HyperC has a fully functional metaplanner - the implementation of PDDL planner in terms of HyperC Python (only the problem of planning is defined, not the actual algorithms) . ",
    "url": "https://hyperc.ai/architecture/#recursive-planning",
    "relUrl": "/architecture/#recursive-planning"
  },"4": {
    "doc": "Architecture",
    "title": "Components",
    "content": "HyperC Planning Database consists of: . | hyperc Python module: implements core logic of sumbolic execution of Python | hyper-etable module is responsible for interpreting the data schemas into Python code | postgresql proxy manages database connections and adds rewriters for TRANSIT* queries | PostgreSQL database implements standards-compatible interfaces, process and lock management | . ",
    "url": "https://hyperc.ai/architecture/#components",
    "relUrl": "/architecture/#components"
  },"5": {
    "doc": "Architecture",
    "title": "Learning",
    "content": " ",
    "url": "https://hyperc.ai/architecture/#learning",
    "relUrl": "/architecture/#learning"
  },"6": {
    "doc": "Architecture",
    "title": "Architecture Diagram",
    "content": ". ",
    "url": "https://hyperc.ai/architecture/#architecture-diagram",
    "relUrl": "/architecture/#architecture-diagram"
  },"7": {
    "doc": "Architecture",
    "title": "Architecture",
    "content": " ",
    "url": "https://hyperc.ai/architecture/",
    "relUrl": "/architecture/"
  },"8": {
    "doc": "Documentation",
    "title": "General Structure",
    "content": "HyperC is composed of a core library hyperc, the relational data interpretation layer hyper-etable, database interoperability hyperc-psql-proxy and a nice Python integration module called ordered . HyperC has a layered approach (see architecture) centered around Python and PDDL. You define the data in objects of types (or rows of tables in database terminology), define procedures or actions that can modify the data, and the goal state to reach. HyperC will then select the correct procedures to run to get to that state. You can choose to write procedures directly as pure Python files and run with ordered or you can work with a pre-packaged PostgreSQL interface that offers built-in data management, procedure storage and planning in one package. The ability to write and test procedures in Python may be helpful to construct and debug larger models. ",
    "url": "https://hyperc.ai/documentation/#general-structure",
    "relUrl": "/documentation/#general-structure"
  },"9": {
    "doc": "Documentation",
    "title": "Gentle Intro Example",
    "content": "To understand goal-oriented programming, let’s look at the simplest example in Python: . from hyperc import solve class Numbers: i: int n0 = Numbers() n0.i = 0 def inc(n: Numbers): n.i += 1 def goal(n: Numbers): assert n.i == 3 solve(goal) print(n0.i) # =&gt; 3 . This code defines the end goal to solve for a state where some object of type Numbers will have &lt;object Numbers&gt;.i == 3. Given is the function that takes object and increments the property i and one object with a star value .i=0. The resulting plan when HyperC solves this is: . inc(n0) inc(n0) inc(n0) . The same task in the database will look like this: . CREATE TABLE numbers ( id integer PRIMARY KEY, i integer ); INSERT INTO numbers VALUES (0, 0); CREATE PROCEDURE inc(n numbers) LANGUAGE 'hyperc' AS $$ n.I += 1 $$; TRANSIT UPDATE numbers SET i = 3; . the TRANSIT UPDATE command tells HyperC to reach the state of the table numbers that would have been set by the proposed UPDATE. Note that we always have to have some KEY column in the table that will not be modified, so we had to create an additional id column. Also as databases don’t distinguish column name case, uppercase column names is a requirement. You will get the output . step_num | proc_name | op_type -----------+------------+--------- 0 | inc | STEP 1 | inc | STEP 2 | inc | STEP -1 | UPDATE . and as expected, . SELECT * FROM numbers; id | i ----+--- 0 | 3 (1 row) . we can try to roll back using TRANSIT UPDATE: . TRANSIT UPDATE numbers SET i = 0; ERROR: hyperc.exceptions.SchedulingError: Obtained proof that task has no solution . which obviously fails as there is no set of procedures that could be applied to set the column i to 0. Sending a normal UPDATE will fix the table back to original state: . UPDATE numbers SET i = 0; UPDATE 1 SELECT * FROM numbers; id | i ----+--- 0 | 0 (1 row) . ",
    "url": "https://hyperc.ai/documentation/#gentle-intro-example",
    "relUrl": "/documentation/#gentle-intro-example"
  },"10": {
    "doc": "Documentation",
    "title": "Procedures Programming",
    "content": "HyperC accepts writing procedures in a subset of Python language. By writing the procedures, you define the allowed transitions within the database. We refer to a complete set of procedures as the “business schema”. Let’s use this code as an example: . def move_truck(truck: Trucks, waypoint_pair: Waypoints): assert truck.LOCATION == waypoint_pair.FROM_LOCATION truck.LOCATION = waypoint_pair.TO_LOCATION truck.ODOMETER += waypoint_pair.POINTS_DISTANCE . When adding the code to the database, the procedure can be created with: . CREATE PROCEDURE move_truck(t trucks, l location_adjacency) LANGUAGE 'hyperc' AS $BODY$ assert truck.LOCATION == waypoint_pair.FROM_LOCATION truck.LOCATION = waypoint_pair.TO_LOCATION truck.ODOMETER += waypoint_pair.POINTS_DISTANCE $BODY$; . Which is almost exact equivalent aside from that it’s not indented. The line with assert defines the condition when this function can be run - when objects truck and waypoint_pair are related in a way that LOCATION property of truck equals FROM_LOCATION of waypoint_pair. You can think of this constraint as a JOIN between tables Trucks and Waypoints but with only a single pair of them taken from the join when a function is executed. The last two lines update the respective values of a row (object). There is a limit of what can be done in HyperC’ Python dialect: only plain Python is supported with if/assert, integers, bools and strings. ",
    "url": "https://hyperc.ai/documentation/#procedures-programming",
    "relUrl": "/documentation/#procedures-programming"
  },"11": {
    "doc": "Documentation",
    "title": "Query Language",
    "content": "HyperCDB is based on PostgreSQL database v.14 and most functions of the database work as expected. We extend SQL language with the TRANSIT * set of commands: . ",
    "url": "https://hyperc.ai/documentation/#query-language",
    "relUrl": "/documentation/#query-language"
  },"12": {
    "doc": "Documentation",
    "title": "Initializing Tables",
    "content": "TRANSIT INIT . Prepares the database for planning function. ",
    "url": "https://hyperc.ai/documentation/#initializing-tables",
    "relUrl": "/documentation/#initializing-tables"
  },"13": {
    "doc": "Documentation",
    "title": "TRANSIT",
    "content": "[ EXPLAIN [ TO table_name1[.column], table_name2, ... ]] TRANSIT UPDATE table_name SET { column = { expression | DEFAULT } | ( column [, ...] ) = ( { expression | DEFAULT } [, ...] ) } [, ...] [ WHERE condition ] . Returns . A table with the plan. Description . TRANSIT UPDATE initiates transition to the state defined by UPDATE statement with familiar SQL syntax of UPDATE. It returns the table of the plan with unique plan_id that can be remembered and used to query hc_plan table to recall this plan at any later time. EXPLAIN TRANSIT ... - initiates calculation of the plan, stores and outputs the plan table but does not do any actual updates to the state. EXPLAIN TO *table_name*, ... TRANSIT ... - instructs the solver to only write down changes to tables (and possibly columns) specified after TO keyword. Examples: . Calculate transition plan but only write down odometer reading, leaving truck at its original location: . EXPLAIN TO trucks.odometer TRANSIT UPDATE trucks SET location = 'Office'; . hc_plan table . HyperCDB defines a special table hc_plan to incrementally store all plans with called procedure names and input/output parameters in JSONB objects. The purpose of hc_plan table is to easily extract additional information from the plans like tracing the truck travel path, measuring fuel consumption, etc. When TRANSIT command completes, it outputs the plan table back to the user connection. plan_id can be extracted and remembered by the client application to select this plan from later. ",
    "url": "https://hyperc.ai/documentation/#transit",
    "relUrl": "/documentation/#transit"
  },"14": {
    "doc": "Documentation",
    "title": "Documentation",
    "content": ". | General Structure | Gentle Intro Example | Procedures Programming | Query Language . | Initializing Tables | TRANSIT . | Returns | Description | hc_plan table | . | . | . ",
    "url": "https://hyperc.ai/documentation/",
    "relUrl": "/documentation/"
  },"15": {
    "doc": "Home",
    "title": "HyperCPlanning Database",
    "content": ". ",
    "url": "https://hyperc.ai/",
    "relUrl": "/"
  },"16": {
    "doc": "Home",
    "title": "About HyperCDB",
    "content": "HyperC Planning Database enables processing of data and business rules with autonomous algorithms. HyperCDB finds best-effort-optimal plans in retail, logistics, robotics, IT infrastructure and others using action schema defined with an easy domain-independent language. HyperCDB reads stored PostgreSQL procedures written in Python and applies only relevant of them repeatedly to reach a desired end state. It achieves this by gradually lowering the logic order of defined procedures to selected grounded states. The math behind HyperC lies in realms of AI planning, automatic proof and type theory. ",
    "url": "https://hyperc.ai/#about-hypercdb",
    "relUrl": "/#about-hypercdb"
  },"17": {
    "doc": "Home",
    "title": "Transitional Database vs. Transactional Database",
    "content": "HyperCDB is a transitional, or planning database. This means that instead of blindly accepting an UPDATE to the stored data, HyperCDB calculates if it is possible to reach the new proposed state using the allowed transitions. This transitional property is useful in several scenarios: . | Validating every change to the data to be in compliance with defined business process | Generating missing data and performing consistency healing automatically | Planning restocking, checking manufacturing timings, allocating workforce, etc. | Rebalancing cloud clusters with complex resource dependencies and constraints | Robotic motion planning for 3D printers, cutters, and multi-axis robots | Automatic website design | Creating spacecraft launch sequences | etc. | . ",
    "url": "https://hyperc.ai/#transitional-database-vs-transactional-database",
    "relUrl": "/#transitional-database-vs-transactional-database"
  },"18": {
    "doc": "Home",
    "title": "Getting Started with HyperCDB",
    "content": "Installation . docker run -p 8493:8493 hypercdb/hypercdb . Then connect to the database using pgAdmin or your favorite PostgreSQL admin tool. Demo project user is pguser and password is 123. To run with persistent data, use: . docker run --name hyperc -p 8493:8493 -v &lt;path to your local folder&gt;:/opt/hyperc/db/data hypercdb/hypercdb . Create your first plan . HyperCDB docker image comes with a demo database with vehicles in trucks table and map defined in location_adjacency table. To create a plan for the trucks to move, issue the TRANSIT query: . $ psql -h localhost --port 8493 -U pguser testdb . testdb=&gt; SELECT * FROM trucks; name | odometer | location ---------+----------+---------- Truck 2 | 0 | Office Truck 1 | 0 | Home testdb=&gt; TRANSIT UPDATE trucks SET location = 'Office'; step_num | proc_name -----------+------------- 0 | move_truck 1 | move_truck ... testdb=&gt; SELECT * FROM trucks; name | odometer | location ---------+----------+---------- Truck 2 | 0 | Office Truck 1 | 7 | Office . TRANSIT queries tell HyperC to calculate transition plan instead of ‘just’ accepting the change. You will also notice that odometer reading was updated automatically, as move_truck procedure was also counting mileage at every execution. ",
    "url": "https://hyperc.ai/#getting-started-with-hypercdb",
    "relUrl": "/#getting-started-with-hypercdb"
  },"19": {
    "doc": "Home",
    "title": "Preparing Database From Scratch",
    "content": "Initializing database . HyperCDB requires special table hc_plan and procedure hyperc_transit to be initialized in the database so you must always explicitly issue this command: . TRANSIT INIT; . You must be connected to correct database before issuing TRANSIT INIT. Creating tables . Creating tables works exactly the same as in any PostgreSQL database with additional requirement that all tables must have PRIMARY KEY defined: . CREATE TABLE public.trucks ( name character varying(50) PRIMARY KEY NOT NULL, odometer integer, location character varying(50) NOT NULL ); . Creating transition procedures . All transition procedures must have language 'hyperc' and define one or more input parameters. Column names must be all capital letters in current edition of HyperCDB procedure language: . CREATE PROCEDURE move_truck(t trucks, l location_adjacency) LANGUAGE 'hyperc' AS $BODY$ assert t.LOCATION == l.LOC_A t.LOCATION = l.LOC_B t.ODOMETER += l.DISTANCE $BODY$; . Procedure move_truck(t truck, l location_adjacency) takes two rows as input: any row from trucks table as local variable t and any row from location_adjacency table with local name l. Additional information on defining stored procedures can be found in PostgreSQL manual. HyperC will automatically define which rows have the best match to reach end state in least steps. The body of the procedure is defined in Python-like dialect: . assert t.LOCATION == l.LOC_A t.LOCATION = l.LOC_B t.ODOMETER += l.DISTANCE . The first line, assert t.LOCATION == l.LOC_A means that only such two rows (t from trucks and l from location_adjacency) that have equal values in columns location and loc_a respectively can be used in this procedure. The business logic behind this assertion is that we want to ‘JOIN’ tables trucks and location_adjacency by columns LOCATION and LOC_A because the truck can only move to the next adjacent location, defined in columns LOC_A and LOC_B in locations adjacency map table. The second and third lines define the effects of the procedure: updating location of the truck to next hop from the table, and increasing the odometer. ",
    "url": "https://hyperc.ai/#preparing-database-from-scratch",
    "relUrl": "/#preparing-database-from-scratch"
  },"20": {
    "doc": "Home",
    "title": "Status",
    "content": "HyperC in under active development. It is used in several production environments but has scalability limitations that are being addressed using various machine learning techniques. ",
    "url": "https://hyperc.ai/#status",
    "relUrl": "/#status"
  },"21": {
    "doc": "Home",
    "title": "Support",
    "content": "HyperCDB is supported by HyperC team. Feel free to write at andrew@hyperc.com. ",
    "url": "https://hyperc.ai/#support",
    "relUrl": "/#support"
  },"22": {
    "doc": "Home",
    "title": "Home",
    "content": ". ",
    "url": "https://hyperc.ai/",
    "relUrl": "/"
  },"23": {
    "doc": "Scalability",
    "title": "Scalability Challenge",
    "content": "Planning problems are known to scale poorly with conventional approaches. They require extreme amounts of RAM and compute to create plans with the real-world dataset. This document briefly discusses HyperC approach to the scalability challenge of the planning database. What is a Scalability Problem? . | Planning 10 items delivery with 10 steps takes 10MB of RAM and 30 seconds | Planning 1000 items with 20 steps needs 1’000’000 MB or RAM and 3e10 seconds | . In other words, state-space grows very fast with the amount of data that needs to be processed. ",
    "url": "https://hyperc.ai/scalability/#scalability-challenge",
    "relUrl": "/scalability/#scalability-challenge"
  },"24": {
    "doc": "Scalability",
    "title": "Previous Approaches",
    "content": "Other than applying a hardcoded domain-specific method for a particular sub-problem, several universal approaches are in use for solving planning problems: . ",
    "url": "https://hyperc.ai/scalability/#previous-approaches",
    "relUrl": "/scalability/#previous-approaches"
  },"25": {
    "doc": "Scalability",
    "title": "Multiagent Systems",
    "content": "The idea is to define a problem with independent “agents” that communicate and make decisions independently. It is very easy to scale multi-agent task to many CPUs. The issue is that very few real-world processes act like independent agents and even if agents are present, the “actions” of the agents are highly dependent on each other. Additionally, multi-agent programming requires more brainpower than free-form modeling and is not popular. ",
    "url": "https://hyperc.ai/scalability/#multiagent-systems",
    "relUrl": "/scalability/#multiagent-systems"
  },"26": {
    "doc": "Scalability",
    "title": "GPU-based Methods",
    "content": "Various GPU-based methods are under development. The challenge with applying GPUs is that GPUs have a specific architecture optimized for thousands of threads that must operate under the same execution flow branch. Whenever the threads stop being “in sync” the vectorized execution breaks and performance falls back to single-threaded. A typical planning problem is about exploring many different branches, so advanced trickery is required to set up such a task for the GPU. This makes crafting an efficient GPU-bound planning task extra challenging and could be intractable for humans to complete without a universal task translator, which does not exist yet. ",
    "url": "https://hyperc.ai/scalability/#gpu-based-methods",
    "relUrl": "/scalability/#gpu-based-methods"
  },"27": {
    "doc": "Scalability",
    "title": "LP- and SAT- based Methods",
    "content": "An approach based on scalable LP- and SAT- solvers is the most widespread among the Operations Research community. It also provides the most performing solutions without any additional compute-heavy training or tuning step. The downside is that a specific skillset and experience is required to convert any real-world problem into an LP or SAT formalism. Additionally, any seemingly insignificant change to the problem definition may require a complete rewrite of the solution, multiplying the time and cost to develop. ",
    "url": "https://hyperc.ai/scalability/#lp--and-sat--based-methods",
    "relUrl": "/scalability/#lp--and-sat--based-methods"
  },"28": {
    "doc": "Scalability",
    "title": "Hierarchical Task Networks",
    "content": "HTNs have seen the most success as a universal approach to scalable planning in various applications. The downside is that it combines the features and issues of the above methods. It requires high engagement of the developer into managing and hand-tuning the problem definition and also experience that is hard to obtain quickly. ",
    "url": "https://hyperc.ai/scalability/#hierarchical-task-networks",
    "relUrl": "/scalability/#hierarchical-task-networks"
  },"29": {
    "doc": "Scalability",
    "title": "Our Approach",
    "content": "HyperC takes a novel approach to the problem that can be nicknamed as “decompose and reuse”. Decompose means that we split the problem into many smaller sub-problems. The major implementation of this principle is in the “gradual grounding” approach where the highest-level expressivity construct (the database engine query) is being interpreted as a set of Python statements, then the ambiguities in Python variables are interpreted, and so on… . Reuse means that we use the system to optimize itself. The planning problem can be expressed as a planning problem. The automatic proof can be expressed as a planning problem, and so on. So we solve the planning problem and reuse the solver recursively. ",
    "url": "https://hyperc.ai/scalability/#our-approach",
    "relUrl": "/scalability/#our-approach"
  },"30": {
    "doc": "Scalability",
    "title": "The Task",
    "content": ". | Given the poorly defined problem in expressive and non-deterministic formalism - optimize it for better performance | Given we have a solution for small amount of items/trucks/logic steps, figure out how to solve for larger amount. | . The first definition comes from the fact that it is very hard to isolate a “pure” problem from a real-world process so we expect the original definition to have unnecessary actions, effects, and missing “obvious” constraints. The model of the domain itself will have unnecessary detail that will pollute the heap with irrelevant or redundant facts and statements. The second subtask is about learning to solve smaller problems and applying the knowledge to try to solve larger onces. ",
    "url": "https://hyperc.ai/scalability/#the-task",
    "relUrl": "/scalability/#the-task"
  },"31": {
    "doc": "Scalability",
    "title": "Select the Right Formalism",
    "content": "HyperC uses: . | STRIPS formalism | Strictly first-order logic | Filter everything through a layer of a subset of PDDL | . This allows us to apply a large corpus of research and algorithms that exists in AI planning domain. For example it has been shown that sound plans can always be found if enough states (interpretations) are grounded. ",
    "url": "https://hyperc.ai/scalability/#select-the-right-formalism",
    "relUrl": "/scalability/#select-the-right-formalism"
  },"32": {
    "doc": "Scalability",
    "title": "Scaling Problem in STRIPS formalism",
    "content": "In STRIPS, we can define the scaling problem with two statements: . | Find smaller grounding to be able to do an exhaustive search | Use universal heuristics to search better than blind | . It is easy to see that the smaller state-space resulting from fewer interpretations will allow to solve the problem much faster even without any additional heuristics. The universal heuristics can be applied from existing research as well as machine-learned on a concrete problem, a set of problems or universally with domain-independent embedding. ",
    "url": "https://hyperc.ai/scalability/#scaling-problem-in-strips-formalism",
    "relUrl": "/scalability/#scaling-problem-in-strips-formalism"
  },"33": {
    "doc": "Scalability",
    "title": "Scaling Mechanisms that Work",
    "content": ". | Ahead-of-time Identity Interpretation - pre-computed interpretations of variable/object identity to reduce amount of absurd interpretations | Automatic Side-Effect (ASE) - automatic proof that part of the definition has no effect on solution or plan and is safe to remove, reducing amount of objects/ | Action schema splitting - Action schema optimization based on breaking down big action schemas into smaller schemas with smaller interpretation/grounding | Domain and fact-space cleanup removes unused actions and facts prior to running “smarter” portions of the system. | Caching of function interpretations skips some compilation and optimization steps | . Low-hanging Fruits . | Select only relevant records from the database | Parallel symbolic execution | . ",
    "url": "https://hyperc.ai/scalability/#scaling-mechanisms-that-work",
    "relUrl": "/scalability/#scaling-mechanisms-that-work"
  },"34": {
    "doc": "Scalability",
    "title": "Tested Methods not yet in Production",
    "content": ". | Machine learned partial grounding - reduces the search space by analyzing the existing plans and inferring additional knowledge about the domain. Shown to accelerate search by 1000x | Genetic programming-based heuristic configuration optimization: Fast-downward, the underlying solver comes with a powerful search configuration language that allows construction of novel domain-specific heuristics. GP shown to accelerate by 1000x. | Schema splitting optimization - configuring parameters of splitter function and heuristics to yield optimal grounding | Reordering of preconditions [assign order scores to preconditions] - optimizing grounding path, splitter performance and search direction by reordering the precondtions | . ",
    "url": "https://hyperc.ai/scalability/#tested-methods-not-yet-in-production",
    "relUrl": "/scalability/#tested-methods-not-yet-in-production"
  },"35": {
    "doc": "Scalability",
    "title": "Methods from literature but not fully tested yet",
    "content": ". | Schema modification using automatic proof a. Interpreted without data (ex. bound propagation) b. Interpreted with data (ex. ALEPH) c. [In between] | Learning new proof methods / partial plans from solved plans | . ",
    "url": "https://hyperc.ai/scalability/#methods-from-literature-but-not-fully-tested-yet",
    "relUrl": "/scalability/#methods-from-literature-but-not-fully-tested-yet"
  },"36": {
    "doc": "Scalability",
    "title": "Novel Work not in production yet",
    "content": ". | Metaplanner - recursive planner that defines and loads the planning problem as a planning problem. Creates universal embedding for machine learning. Applicable for infinite recursion of many “meta-levels” | Hinting - simplified machine learning embeddable in PDDL domain definition directly: calculate sets of objects that can be selected by a specific action and injects as preconditions. Requires stabilization of object hashes. | . ",
    "url": "https://hyperc.ai/scalability/#novel-work-not-in-production-yet",
    "relUrl": "/scalability/#novel-work-not-in-production-yet"
  },"37": {
    "doc": "Scalability",
    "title": "Not-distant Future",
    "content": ". | Grounding mining. Some problems may never fit into computer memory or be optimally solved (for example the task of task optimization). Grounding mining is a partial groudnging approach that works like a combination of a lifted planning and machine learned grounding. Should be better than lifted planning and blind search. Should only be applied at meta level (for tasks of optimizing the tasks and search). | Deep meta applications of the planner a. Searching for a heuristic for better heuristic… b. Optimizing the task optimizer for task optimizer… | . ",
    "url": "https://hyperc.ai/scalability/#not-distant-future",
    "relUrl": "/scalability/#not-distant-future"
  },"38": {
    "doc": "Scalability",
    "title": "Remark on Plan Optimality",
    "content": "HyperC aims at outperforming humans at planning problems. So we provide no guarantee of optimality of the plan, nor do we provide any safety of the solution. However, some modes include double-evaluation using Python so plan correctness can be asserted with high level of confidence. Thus HyperC is allowed to “cut corners” and “cheat” in order to find feasible solutions faster. ",
    "url": "https://hyperc.ai/scalability/#remark-on-plan-optimality",
    "relUrl": "/scalability/#remark-on-plan-optimality"
  },"39": {
    "doc": "Scalability",
    "title": "Scalability",
    "content": ". | Scalability Challenge . | What is a Scalability Problem? | . | Previous Approaches . | Multiagent Systems | GPU-based Methods | LP- and SAT- based Methods | Hierarchical Task Networks | . | Our Approach . | The Task | Select the Right Formalism | Scaling Problem in STRIPS formalism | Scaling Mechanisms that Work . | Low-hanging Fruits | . | Tested Methods not yet in Production | Methods from literature but not fully tested yet | Novel Work not in production yet | Not-distant Future | . | Remark on Plan Optimality | . ",
    "url": "https://hyperc.ai/scalability/",
    "relUrl": "/scalability/"
  }
}
